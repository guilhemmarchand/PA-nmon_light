# props.conf

###########################################
#			nmon converted csv stanza			#
###########################################

# This sourcetype stanza will be used to index nmon csv converted data
# Every generated csv file will contain a CSV header used by Splunk to identify fields

[nmon_data]

FIELD_DELIMITER=,
FIELD_QUOTE="
HEADER_FIELD_LINE_NUMBER=1

# your settings
INDEXED_EXTRACTIONS=csv
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=false
TIMESTAMP_FIELDS=ZZZZ
TIME_FORMAT=%d-%m-%Y %H:%M:%S

# set by detected source type
KV_MODE=none
pulldown_type=true

# Leaving PUNCT enabled can impact indexing performance, and uses space
# For structured data, it has poor interest and shall be deactivated
ANNOTATE_PUNCT=false

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_data_hostoverride

###########################################
#			nmon perf data JSON
###########################################

# New with 1.2.55, allows the performance data to be generated in json format

# This the indexed time json format
[nmon_data:json:indexed]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
CHARSET=UTF-8
INDEXED_EXTRACTIONS=json
KV_MODE=json
disabled=false
pulldown_type=true
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIMESTAMP_FIELDS=ZZZZ

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_data_json_hostoverride

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-nmon_data_json_sourcetypeoverride = nmon_data_json_sourcetypeoverride

# Leaving PUNCT enabled can impact indexing performance, and uses space
# For structured data, it has poor interest and shall be deactivated
ANNOTATE_PUNCT=false

# This is the extracted search time json format
[nmon_data:json:extracted]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
CHARSET=UTF-8
disabled=false
pulldown_type=true
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIME_PREFIX = \"ZZZZ\":\s"
KV_MODE=json

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_data_json_hostoverride

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-nmon_data_json_sourcetypeoverride = nmon_data_json_sourcetypeoverride

# Leaving PUNCT enabled can impact indexing performance, and uses space
# For structured data, it has poor interest and shall be deactivated
ANNOTATE_PUNCT=false

# For search heads, manage the KV_MODE from source for json indexed data
[source::perfdata:json:indexed]
KV_MODE=none

# For search heads, manage the KV_MODE from source for json extracted data
[source::perfdata:json:extracted]
KV_MODE=json

# Additional: In full extracted mode, we want 2 basic Nmon extracted at indexed time
TRANSFORMS-nmon_data_json_createindexed_time = nmon_data_json_createindexed_OStype, nmon_data_json_createindexed_type

###########################################
#			nmon processing stanza
###########################################

[nmon_processing]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
BREAK_ONLY_BEFORE=\d{2}-\d{2}-\d{4}\s\d{2}:\d{2}:\d{2}\sReading\sNMON\sdata
CHARSET=UTF-8
MAX_TIMESTAMP_LOOKAHEAD=40
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TRUNCATE=0
MAX_EVENTS=100000

KV_MODE=none

# For TA-nmon
EXTRACT-splunk_home = (?i).+\w*\sRoot\sDirectory\s\(\$SPLUNK_HOME\)\:\s{0,}(?P<splunk_home>[a-zA-Z0-9\/\\\-\_\.\:]+)\s

# For nmon-logger
EXTRACT-nmon_home = (?i).+\w*\sRoot\sDirectory\s\(\$NMON_VAR\)\:\s{0,}(?P<nmon_var>[a-zA-Z0-9\/\\\-\_\.\:]+)\s
EXTRACT-operating_system = (?i).+Guest\sOperating\sSystem\:\s{0,}(?P<operating_system>[a-zA-Z0-9]+)\s
EXTRACT-addon_type = (?i).*addon\s*type:\s.*\/(?<addon_type>[a-zA-Z0-9|\-\_]+)\s
EXTRACT-addon_version = (?i).+addon\sversion\:\s{0,}(?P<addon_version>[a-zA-Z0-9\.]+)\s
EXTRACT-python_version = (?i).+Python\sversion\:\s{0,}(?P<python_version>[a-zA-Z0-9\.]+)\s
EXTRACT-perl_version = (?i).+Perl\sversion\:\s{0,}(?P<perl_version>[a-zA-Z0-9\.]+)\s
EVAL-converter_inuse = case(isnotnull(python_version), "Python", isnotnull(perl_version), "Perl")
EVAL-interpreter_version = case(isnotnull(python_version), python_version, isnotnull(perl_version), perl_version)
EXTRACT-nmon2csv_version = (?i).+nmon2csv\sversion\:\s{0,}(?P<nmon2csv_version>[0-9\.]+)\s
EXTRACT-hostname = (?i).+HOSTNAME\:\s{0,}(?P<hostname>[a-zA-Z0-9\-\_\.]+)
EXTRACT-nbr_lines = (?i).+Reading\sNMON\sdata:\s{0,}(?P<nbr_lines>\d+)\slines
EXTRACT-size_in_bytes = (?i).+lines\s(?P<size_in_bytes>\d+)\sbytes
EXTRACT-elapsed_in_seconds = (?i).+Elapsed\stime\swas\:\s{0,}(?P<elapsed_in_seconds>\d+\.\d+)\sseconds
EXTRACT-Nmon_version = (?i).+NMON\sVERSION\:\s{0,}(?P<Nmon_version>[a-zA-Z0-9\-\_\.\s]+)\s
EXTRACT-Time_of_Nmon_data = (?i).+TIME\sof\sNmon\sData\:\s{0,}(?P<Time_of_Nmon_Data>[0-9\:\.]+)\s
EXTRACT-Date_of_Nmon_data = (?i).+DATE\sof\sNmon\sData\:\s{0,}(?P<Date_of_Nmon_Data>[a-zA-Z0-9\-\/]+)\s
EXTRACT-INTERVAL = (?i).+INTERVAL\:\s{0,}(?P<INTERVAL>\d+)\s
EXTRACT-SNAPSHOTS = (?i).+SNAPSHOTS\:\s{0,}(?P<SNAPSHOTS>\d+)\s
EXTRACT-logical_cpus = (?i).+logical_cpus\:\s{0,}(?P<logical_cpus>\d+)\s
EXTRACT-virtual_cpus = (?i).+virtual_cpus\:\s{0,}(?P<virtual_cpus>\d+)\s
EXTRACT-Nmon_ID = (?i).+NMON\sID\:\s{0,}(?P<Nmon_ID>[a-zA-Z0-9\-\:\,\_\.]+)\s

###########################################
#			nmon config stanza					#
###########################################

[nmon_config]

BREAK_ONLY_BEFORE=CONFIG,
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%d-%b-%Y:%H:%M
TIME_PREFIX=CONFIG,
TRUNCATE=0

# Deactivate KV
KV_MODE = none

EXTRACT-hostname = (?i)AAA,host,(?P<hostname>[a-zA-Z0-9\-\_\.]+)\s

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_config_hostoverride

# Perform basic extractions
# Full extractions can be performed by calling associated macros, or using the data model
EXTRACT-AAA_OS = (?i),OS,(?P<AAA_OS>[^,]+)\s{0,}
EXTRACT-AIX_LEVEL = AAA,AIX,(?P<AIX_LEVEL>[a-zA-Z0-9\-\_\.]+)\s
EXTRACT-Linux_LEVEL = AAA,OS,Linux,(?P<Linux_LEVEL>[^,]+),
EXTRACT-Solaris_LEVEL = AAA,OS,Solaris,(?P<Solaris_LEVEL>[^,]+),
EVAL-OStype = case(AAA_OS == "Linux", "Linux", AAA_OS == "Solaris", "Solaris", isnotnull(AIX_LEVEL), "AIX", isnull(AAA_OS), "Unknown")

# When applicable, be CIM compliant

FIELDALIAS-dest = host as dest
EXTRACT-AAA_serial = AAA,SerialNumber,(?<AAA_serial>\w*)
EVAL-serial = if(isnotnull(AAA_serial), AAA_serial, host)
EVAL-hypervisor_id = if(isnotnull(AAA_serial), AAA_serial, hostname)
EVAL-hypervisor = if(isnotnull(AAA_serial), AAA_serial, hostname)

# family
EXTRACT-AIX_processor_type = BBB\w*,[^,]+,lsconf,\"Processor\sType:\s(?<AIX_processor_type>\w*)\"
EXTRACT-Linux_processor_type = AAA,OS,Linux,[^,]+,[^,]+,(?<Linux_processor_type>\w*)
EXTRACT-Solaris_processor_type = BBB.+,[0-9].+psrinfo\s\-pv,\"\s+(?P<Solaris_processor_type>[\w\-\_]*)\s*\(.+\"
EVAL-family = case(isnotnull(Linux_LEVEL), Linux_processor_type, isnotnull(Solaris_LEVEL), Solaris_processor_type, isnotnull(AIX_LEVEL), AIX_processor_type)

# Vendor / Product
EXTRACT-Linux_release_distribution = BBB\w*,[^,]*,.+etc+.release,\"(?!LSB_VERSION|DISTRIB|NAME|ID|VERSION)(?P<Linux_release_distribution>[^,]+)\"
EXTRACT-Linux_lsb_distribution = BBB\w*,[^,]*,lsb_release,\"Description:\s*(?<Linux_lsb_distribution>[^,]*)\"
EVAL-Linux_distribution = if(isnotnull(Linux_lsb_distribution), Linux_lsb_distribution, Linux_release_distribution)
EXTRACT-Solaris_version = BBB\w*,[^,]*,.+etc+.release,\"\s+(?P<Solaris_version>Oracle\s*Solaris\s[^\"]*)\"
EVAL-AIX_version = case(isnotnull(AIX_LEVEL), "IBM AIX" + " " + AIX_LEVEL)

EVAL-vendor_product = case(isnotnull(Linux_LEVEL), (if(isnotnull(Linux_lsb_distribution), Linux_lsb_distribution, Linux_release_distribution)), isnotnull(Solaris_LEVEL), Solaris_version, isnotnull(AIX_LEVEL), "IBM AIX " + 'AIX_LEVEL' )
EVAL-version = case(isnotnull(Linux_LEVEL), Linux_LEVEL, isnotnull(Solaris_LEVEL), Solaris_LEVEL, isnotnull(AIX_LEVEL), AIX_LEVEL )
EVAL-os = case(isnotnull(Linux_LEVEL), (if(isnotnull(Linux_lsb_distribution), Linux_lsb_distribution, Linux_release_distribution)), isnotnull(Solaris_LEVEL), Solaris_version, isnotnull(AIX_LEVEL), "IBM AIX " + 'AIX_LEVEL' )

# CPU
EXTRACT-AIX_virtualcpus = BBB\w*,[^,]+,lparstat\s-i,\"Online\sVirtual\sCPUs\s*:\s*(?<AIX_virtualcpus>\d*)\"
EXTRACT-cpu_cores_position1 = AAA,cpus,(?P<cpu_cores_position1>\d+)
EXTRACT-cpu_cores_position2 = AAA,cpus,\d+,(?P<cpu_cores_position2>\d+)
EVAL-cpu_cores_combo = (AIX_virtualcpus+" / "+cpu_cores_position2)

EVAL-cpu_cores = if(isnotnull(AIX_virtualcpus), AIX_virtualcpus, cpu_cores_position1)
EVAL-cpu_count = case(isnotnull(AIX_LEVEL), AIX_virtualcpus, isnotnull(Solaris_LEVEL), cpu_cores_position1, isnotnull(Linux_LEVEL), cpu_cores_position1)

EXTRACT-Solaris_processor_clockspeed = BBB.+,[0-9].+psrinfo\s\-pv,.+clock\s(?P<Solaris_processor_clockspeed>[\d\.]*)\s*\w*\)\"
EXTRACT-Linux_processor_clockspeed_1 = AAA,[^,]+,MHz,(?P<Linux_processor_clockspeed_1>[\d\.]*)
EXTRACT-Linux_processor_clockspeed_2 = BBB\w*,[^,]+,/proc/cpuinfo,\"cpu\s*MHz\s*:\s*(?<Linux_processor_clockspeed_2>[\d\.]*)\"
EXTRACT-Linux_processor_clockspeed_3 = BBB\w*,[^,]+,/proc/cpuinfo,\"clock\s{0,}:\s{0,}(?<Linux_processor_clockspeed_3>[\d|\.]*)\s{0,}MHz\"
EXTRACT-AIX_processor_clockspeed = BBBP,[^,]+,lsconf,"Processor\sClock\sSpeed:\s*(?<AIX_processor_clockspeed>[\d\.]*)\sMHz
EVAL-cpu_mhz = case(isnotnull(Linux_LEVEL), case(isnotnull(Linux_processor_clockspeed_1), Linux_processor_clockspeed_1, isnotnull(Linux_processor_clockspeed_2), Linux_processor_clockspeed_2, isnotnull(Linux_processor_clockspeed_3), Linux_processor_clockspeed_3), isnotnull(Solaris_LEVEL), Solaris_processor_clockspeed, isnotnull(AIX_LEVEL), AIX_processor_clockspeed)

EXTRACT-Linux_realmemory_KB = BBB\w*,[^,]*,/proc/meminfo,\"MemTotal:\s*(?<Linux_realmemory_KB>\d*)\s*kB\"
EXTRACT-Solaris_realmemory_KB = BBB\w*,[^,]*,prtdiag,\"Memory\s*size:\s*(?<Solaris_realmemory_MB>\d*)\sMegabytes\"
EXTRACT-AIX_realmemory_online_MB = BBB\w*,[^,]*,online\s*Memory,(?<AIX_realmemory_online_MB>\d*)
EXTRACT-AIX_realmemory_lsconf_MB = BBB\w*,[^,]*,lsconf,\"Memory\s*Size:\s*(?<AIX_realmemory_lsconf_MB>\d*)\s*MB\"
EVAL-mem = case(isnotnull(Linux_LEVEL), round((Linux_realmemory_KB/1024),0), isnotnull(Solaris_LEVEL), Solaris_realmemory_MB, isnotnull(AIX_realmemory_online_MB), if(isnotnull(AIX_realmemory_online_MB), AIX_realmemory_online_MB, AIX_realmemory_lsconf_MB) )

# Not in CIM
EXTRACT-Linux_swapmemory_KB = BBB\w*,[^,]*,/proc/meminfo,\"SwapTotal:\s*(?<Linux_swapmemory_KB>\d*)\s*kB\"

# Processor extraction
EXTRACT-AIX_processor = BBB\w*,[0-9]*,lsconf,\"Processor\s*Type:\s*(?P<AIX_processor>[^\"]*)\"
EXTRACT-Linux_arch = BBB\w*,[0-9]*,lscpu,\"(Architecture)\s*:\s+(?P<Linux_arch>[^\"]*)\"
EXTRACT-Linux_processor_lscpu = BBB\w*,[0-9]*,lscpu,\"(Model\sname|Model|Vendor\sID)\s*:\s*(?P<Linux_processor_lscpu>[^\"]*)\"
EXTRACT-Linux_processor_cpuinfo = BBB\w*,[0-9].*cpuinfo,\"(model\sname)\s*:\s*(?P<Linux_processor_cpuinfo>[^\"]*)\"
EXTRACT-Solaris_processor_primary = BBB.+,[0-9].+psrinfo\s\-pv,\"\s+(?P<Solaris_processor_primary>.+)\s*\(.+clock.+\"
EXTRACT-Solaris_processor_alt = BBB.+,[0-9].+prtdiag,\"0\s*(?<Solaris_processor_clock_alt>[\d|\.]*\s*\w*)\s*(?P<Solaris_processor_alt>[\w|-]*)\s*
EVAL-processor = case(isnotnull(AIX_LEVEL), AIX_processor, AAA_OS == "Solaris", case(isnotnull(Solaris_processor_primary), Solaris_processor_primary, isnotnull(Solaris_processor_alt), Solaris_processor_alt), AAA_OS == "Linux", case(isnotnull(Linux_processor_lscpu), Linux_processor_lscpu + " (arch: " + Linux_arch + ")" , isnull(Linux_processor_lscpu), Linux_processor_cpuinfo) )

# uptime (available for Linux hosts only)
# Sic !!!
EXTRACT-uptime_days = BBB\w*,[^,]+,uptime,\"\s*[\d|\w|:]*\s*up\s*(?<uptime_days>\d*)\s*day[s|,]*\s*(?<uptime_dayshour>\d*):(?<uptime_daystime>\d*)
EXTRACT-uptime_days_with_min = BBB\w*,[^,]+,uptime,\"\s*[\d|\w|:]*\s*up\s*(?<uptime_days>\d*)\s*day[s|,]*\s*(?<uptime_daysmin>\d*)\smin
EXTRACT-uptime_minutes = BBB\w*,[^,]+,uptime,\"\s*[\d|\w|:]*\s*up\s*(?<uptime_minutes>\d*)\s*min\s*,
EXTRACT-uptime_hours = BBB\w*,[^,]+,uptime,\"\s*[\d|\w|:]*\s*up\s*(?<uptime_hours>\d*:\d*)\s*,
EXTRACT-uptime_hours_hours = BBB\w*,[^,]+,uptime,\"\s*[\d|\w|:]*\s*up\s*(?<uptime_hours_hours>\d*):\d*\s*,
EXTRACT-uptime_hours_minutes = BBB\w*,[^,]+,uptime,\"\s*[\d|\w|:]*\s*up\s*\d*:(?<uptime_hours_minutes>\d*)\s*,
EVAL-uptime_fromdays = (uptime_days*86400)
EVAL-uptime_fromminutes = (uptime_minutes*60)
EVAL-uptime_fromhours = (uptime_hours_hours*60*60) + (uptime_hours_minutes*60)
EVAL-uptime = case(isnotnull(uptime_daysmin), ((uptime_days*86400)+(uptime_daysmin*60)), isnotnull(uptime_days), ((uptime_days*86400)+(uptime_dayshour*3600)+(uptime_daystime*60)), isnotnull(uptime_minutes), (uptime_minutes*60), isnotnull(uptime_hours), (uptime_hours_hours*60*60) + (uptime_hours_minutes*60) )

# CIM Network
REPORT-inventory_network_extractions = inventory_network_interface, inventory_network_ip, inventory_network_mac

##############################################
#			SYSLOG SPECIAL SECTIONS					#
##############################################

# These parameters are dedicated to the deployment of Nmon using syslog as the transport layer
# to forward Nmon Performance data from your end servers to your central syslog, and finally to Splunk

# Deploying Nmon with syslog requires additional configuration on search heads, and potentially indexers
# This also requires specific configuration on end clients (rsyslog/syslog-ng config, cron config, logrotate)

# Data being transferred through syslog is not csv structured data but key=value data
# each source of data is being in a temporary sourcetype for indexing time parsing to occur, then we will
# rewrite the sourcetypes to match standard sourcetypes being used by Core application

# depending on its origin (the source, normal vs syslog), the configuration on the sh head will apply the correct
# extraction parameters at search time.

# The nmon-logger package for Syslog deployment is available at:
# https://github.com/guilhemmarchand/nmon-logger

# Online guides for Syslog deployment:
# rsyslog: http://nmonsplunk.wikidot.com/documentation:installation:rsyslog
# syslog-ng: http://nmonsplunk.wikidot.com/documentation:installation:syslog-ng

####################
# Syslog to Splunk #
####################
#
# If you receive directly from syslog over TCP/UDP, use this sourcetype
# Create a dedicated UDP or TCP input with:
# index = nmon
# source = (leave optional or put anything you like)
# sourcetype = nmon:fromsyslog

# This sourcetype must manage incoming multi / or mono line event
# syslog timestamp is not being used for data time stamping (using nmon timestamp)

#
# Splunk to Splunk is not recommended, prefer having a Splunk instance installed on rsyslog collectors
# or on machine receiving rsyslog data, and generating local per host files
# Therefore, it is still possible to achieve it using a tcp/udp input using this sourcetype:

[nmon:fromsyslog]

BREAK_ONLY_BEFORE=timestamp="
MAX_EVENTS=100000
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
MAX_TIMESTAMP_LOOKAHEAD=26

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS-syslog = syslog-host

# Additional: In full extracted mode, we want 2 basic Nmon extracted at indexed time
TRANSFORMS-nmon_data_kv_createindexed_time = nmon_data_kv_createindexed_OStype, nmon_data_kv_createindexed_type

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_collect
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_clean
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite

#####################################
# Splunk to Splunk with syslog data #
#####################################

# These sourcetypes will be used when reading local files generated by syslog from remote syslog clients
# Each type of data must have its own file monitor.

# See inputs.conf.spec for more information, or read the online wiki manual pages for rsyslog / syslog-ng deployments

#
# For nmon performance data:
#

###################################################
# Set parameters for nmon_data coming from syslog #
###################################################

[nmon_data:fromsyslog]
SHOULD_LINEMERGE=false
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
MAX_TIMESTAMP_LOOKAHEAD=26
KV_MODE=auto

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS-syslog = syslog-host

# Additional: In full extracted mode, we want 2 basic Nmon extracted at indexed time
TRANSFORMS-nmon_data_kv_createindexed_time = nmon_data_kv_createindexed_OStype, nmon_data_kv_createindexed_type

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# For search heads, activate kvmode to auto for that source
[source::perfdata:syslog]
KV_MODE=auto

#
# For nmon configuration data:
#

#####################################################
# Set parameters for nmon_config coming from syslog #
#####################################################

[nmon_config:fromsyslog]
BREAK_ONLY_BEFORE=timestamp="
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
TRUNCATE=0

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS-syslog = syslog-host

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

#
# For nmon processing data:
#

[nmon_processing:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIME_PREFIX=nmon2csv:
CHARSET=UTF-8
BREAK_ONLY_BEFORE=nmon2csv:

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS-syslog = syslog-host

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

#
# For nmon collecting data:
#

[nmon_collect:fromsyslog]

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS-syslog = syslog-host

# Rewrite sourcetype to standard nmon_collect
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

#
# For nmon clean data:
#

[nmon_clean:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
BREAK_ONLY_BEFORE=Starting nmon cleaning
TIME_FORMAT=%c
TIME_PREFIX=\w*\s
CHARSET=UTF-8

# Manage carriage returns sent by syslog
SEDCMD-carriage_return2 = s/#012/\n/g

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS-syslog = syslog-host

# Rewrite sourcetype to standard nmon_clean
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite
